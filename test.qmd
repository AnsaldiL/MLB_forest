---
title: "Machine Learning et prediction d'un couvert forestier"
author: Lucile ANSALDI, Youna DOUCHET, Lucia OLIVEIRA-CRUZ
date: 10/11/2023
editor: visual
format: 
  revealjs :
     slide-number: true
---

## Objectif de l'étude

Prédiction des couverts forestiers à partir de variables cartographiques.

Pourquoi utiliser le **machine learning** ?

-   Pour répertorier le couvert

-   Eviter le déplacement de technicien.ne.s sur place

-   Avoir des informations sur des terres qui ne sont pas sous contrôle direct

## Présentation des données

Données issues utilisées dans une étude de Blackard et Dean, publiée en 1999, provenant du parc National Roosevelt, dans le Colorado.

Le jeu de donné regroupe des données pédologiques et cartographique ainsi que la catégorie de couvert forestier.

```{r}
forest= read.table(file = "covtype.data", sep=",", header=TRUE) 
str(forest)
```

```{r echo = FALSE, include=FALSE}
library(tidyverse)
library(dplyr)
library(FactoMineR)
library(ggplot2)
library(class)
library(ggplot2) # graph package
library(tinytex) # Pour la sortie pdf
library(corrplot)# Correlation matrix calculus
library(glmnet) # multinomiale avec pénalité lasso

a <- rep("Soil_Type_",40)
for (i in 1:40) {
  a[i]<-paste0(a[i],as.character(i))
} 

name <- c("Elevation",
          "Aspect",
          "Slope",
          "Horizontal_Distance_To_Hydrology",
          "Vertical_Distance_To_Hydrology",
          "Horizontal_Distance_To_Roadways",
          "Hillshade_9am",
          "Hillshade_Noon",
          "Hillshade_3pm",
          "Horizontal_Distance_To_Fire_Points",
          "Wilderness_Area_1",
          "Wilderness_Area_2",
          "Wilderness_Area_3",
          "Wilderness_Area_4",
          a,
          "Cover_Type")
colnames(forest)<- name
Cov_type = forest$Cover_Type
Xforest <- subset(forest, select = -Cover_Type)
pcaXforest <- PCA(Xforest, ncp = 2) 
```

## Méthodes testées


![](Demarche.jpg)


## Data driven algorithms

-   K-means

-   K-nearest neighbourg

-   Decision tree

-   Random forest

# Algorithme des K-means

## Code K-means

```{r, echo = TRUE}
n_clusters = length(unique(Cov_type)) # Nombre de cluster attendu : autant que de couverts forestiers possibles
set.seed(1)
i.centers = sample(1:dim(pcaXforest$ind$coord)[1],n_clusters) # initialisation aléatoire des clusters. 
centers = pcaXforest$ind$coord[i.centers,]
km = kmeans(pcaXforest$ind$coord,centers,nstart=10,iter.max=50) # avec 10 sets aléatoires et 50 itérations au maximum
cl = km$cluster # tous les individus sont associés à une classe

cl_lab = cl
for (k in 1:n_clusters){
  ii = which(cl==k) 
  counts=table(Cov_type[ii]) # Nb d'occurences de chaque classe
  imax=which.max(counts) # Calcul de la classe majoritaire
  maj_lab=attributes(counts)$dimnames[[1]][imax] # attribution de l'étiquette de la classe
  print(paste("Classe ",k,", label majoritaire = ",maj_lab))
  cl_lab[ii] = maj_lab
}
```

### 

## Résultat K-means

<div>

```{r accuracy kmeans, echo=FALSE}
accuracy <- sum(cl_lab == Cov_type)/(length(Cov_type))
print(paste("l'accuracy de la classification avec l'algorithme des k-means est de",accuracy)) 
```

```{r, echo=FALSE}
#matrice de confusion et accuracy
confusion = (conf_mat = table(Cov_type,cl_lab, dnn=list("Observed","Predicted")))
```

```{r mat conf kmean}
# représentation de la matrice de confusion
df = as.data.frame(confusion)
df %>% 
  ggplot( aes(x = Observed, y = Predicted, fill = Freq))+
  geom_tile()+
  geom_text(aes(label = round(Freq, 1))) +
  scale_fill_gradient(low="#FFFF88",high="#FF0000")+
  coord_fixed()+
  theme_minimal()+
  ggtitle("Matrice de confusion K-means")+
  theme(axis.text = element_text(size = 12))+
  theme(axis.title = element_text(size = 14))+
  theme(plot.title = element_text(hjust = 0.5))
```

</div>

## Des fréquences déséquilibrées...

```{r freq}
hist(Cov_type, col="orange2", main="Fréquence des types de couverts", xlab="Type de couvert", ylab="Nombre")
```

## Apprentissage supervisé et partitionnement du jeu de données

Séparation du jeu de données de deux manières différentes : - 2/3 train 1/3 test - partitionnement plus fin pour correspondre aux particularité du jeu de données et réduire le temps de calcul

### Fonction de partitionnement :

```{r part_data, echo=TRUE}

part_data <- function(data,freq = rep(1/7,7)){
  # prend en entree le jeu de donnee à echantillonner et un vecteur de fréquences pour chaque classe dans l'ordre (1 à 7)
  # valeur par défaut, toutes les classes sont échantillonnées à peu près à la meme fréquence
  # renvoie les indices des individus de l'echantillon d'entrainement et de l'echantillon de validation
  nb_indiv <- length(data[,1])
  itrain <- c()
  itest <- c(1:nb_indiv)
  # on force l'echantillon d'entrainement à avoir au moins 3 observations par type de sol
  for (i in 15:54) { #les colonnes 14 à 53 sont les colonnes "soil type"
    itrain <- c(itrain,sample(x = which(data[,i] == 1 ),size = 3)) 
  }
  
  # on force l'echantillon d'entrainement à avoir au moins 3 observations par type de sol
  for (i in 11:14) { #les colonnes" 14 à 53 sont les colonnes "soil type""Wilderness_area"
    itrain <- c(itrain,sample(x = setdiff(which(data[,i] == 1 ),itrain),size = 3)) #dans les données pas deja echantilonnee 
  }
  
  # on force l'echantillon d'entrainement à avoir au moins 1000 observations par type de recouvrement végétal
  nb <- freq*7000
  for (i in 1:7) {
    itrain <- c(itrain,sample(x = setdiff(which(data$Cover_Type == i),itrain),size = nb[i]))
  }
  
  itest <- setdiff(itest,itrain)
  itest <- sample(itest,3560) 
  
  return(list(itrain,itest))

}
```
### Utiliser les fréquences de chaque classes 

```{r dataY, include=TRUE}
table(forest$Cover_Type)
freq_cover <- table(forest$Cover_Type)/length(forest$Cover_Type) # en proportions
```

# Méthode K-NN {style=".smaller"}

```{r knn nb n}
C = factor(Cov_type,levels=c(1,2,3,4,5,6,7)) 
nb_Cov_type <- length(unique(Cov_type))

# on va trouver le meilleur nombre de voisin possible pour minimiser l'erreur
nb_neighbors = c(1,5,10,20,25,30,35,40)

n = dim(pcaXforest$ind$coord)[1]
B = 10
err_knn = matrix(0,B,length(nb_neighbors))


for (b in 1:B) { #10 répétitions du modèle 
  set.seed(b)
  
  itrain <- unlist(part_data(forest)[1])
  itest <- unlist(part_data(forest)[2])
  
  
  Xs_train = scale(pcaXforest$ind$coord[itrain,])
  Xs_test = scale(pcaXforest$ind$coord[itest,],center=apply(pcaXforest$ind$coord[itrain,],2,mean),scale=apply(pcaXforest$ind$coord[itrain,],2,sd))
  for (i in 1:length(nb_neighbors)) {
    knn_res = knn(Xs_train,Xs_test,Cov_type[itrain],k=nb_neighbors[i],prob=TRUE)
    err_knn[b,i] = sum(Cov_type[itest]!=knn_res)/length(itest)
  }
  
}

apply(err_knn,2,mean) #on fait la moyenne des col de err_knn 
colnames(err_knn)=nb_neighbors
boxplot(err_knn, main = "Erreur et nombre de voisins", col='orange2') 
w = which.min(apply(err_knn,2,mean)) #le meilleur nombre de voisins
```

## Résultats de la méthode K-NN {style=".smaller"}

Avec le partitionnement des données adapté

```{r include = TRUE}
w = which.min(apply(err_knn,2,mean)) #le meilleur nombre de voisins

n = dim(pcaXforest$ind$coord)[1]
B = 10 # number of samples for the cross validation
y_test = y_prob = NULL
for (b in 1:B){
  set.seed(b)
  
  itrain <- unlist(part_data(forest)[1])
  itest <- unlist(part_data(forest)[2])
  
  Xs_train = scale(pcaXforest$ind$coord[itrain,])
  Xs_test = scale(pcaXforest$ind$coord[itest,],center=apply(pcaXforest$ind$coord[itrain,],2,mean),scale=apply(pcaXforest$ind$coord[itrain,],2,sd))
  knn_res = knn(Xs_train,Xs_test,C[itrain],k=nb_neighbors[w],prob=TRUE)
  y_prob = c(y_prob,attributes(knn_res)$prob)
  y_test = c(y_test,C[itest])
}

#multiclass.roc(y_test, y_prob, level = 7, plot=TRUE) #interet de la courbe ROC..?

Cres <- C[itest]

conf_mat_knn = (conf_mat = table(Cres, knn_res, dnn=list("Predicted", "Observed")))

accuracy <- sum(knn_res == Cres)/(length(Cres))
print(paste("l'accuracy est de :", accuracy))
#0.3579832

# représentation de la matrice de confusion
df = as.data.frame(conf_mat_knn)
df %>% 
  ggplot( aes(x = Observed, y = Predicted, fill = Freq))+
  geom_tile()+
  geom_text(aes(label = round(Freq, 1))) +
  scale_fill_gradient(low="#FFFF88",high="#FF0000")+
  coord_fixed()+
  theme_minimal()+
  ggtitle("Matrice de confusion K-means")+
  theme(axis.text = element_text(size = 12))+
  theme(axis.title = element_text(size = 14))+
  theme(plot.title = element_text(hjust = 0.5))
```

Avec le partitionnement 2/3 et 1/3, l'accurracy monte à 0.5693757

## Algorithme decision tree

## Algorithme random forest


## Modèle driven algorithm

- Modèle multinomial

- Réseau de neuronne 

### Formalisme du modèle multinomial:

$$ Cover \: type \: \sim \: Elevation \: + \: Aspect \: + \: Slope \: + \: ... \: + \: Soil \: type \: 40$$

$Y = Cover \: type$, la variable réponse \
$Xs$ les variables prédictives \

### Valeurs extremes de $X$ 

```{r dataCov, include=TRUE}
par(mfrow=c(2,3))
for (i in 1:10) {
  # Cleveland plot
  boxplot(forest[,i],pch=16,col='salmon',xlab=colnames(forest)[i])
}

```

Les points sans ombre à 9 heures ne sont pas les mêmes que ceux à 12 heures, les valeurs paraissent cohérentes.Les autres valeurs semblent plausibles.

### Répartition des individus pour les variables qualitatives
```{r}
quali <- apply(forest[,11:54], MARGIN = 2, table)
print(as.data.frame(round(100*quali[2,]/(quali[1,]+quali[2,]),digits = 2),optional = TRUE ))
```
En calculant le pourcentage des observations appartenant à chaque classe de "Wilderness area" et de "Soil type, on remarque que Wilderness area 2 et 4 ne représentent respectivement que 5.1 et 6.4 % des observations.  \
\

Pour les types de sols, on remarque que la plupart sont assez peu représentés avec un pourcentage de représentation de l'ordre de $10^{-1}$ ou $10^{0}$. Le type de sol numero 29 est particulièrement représenté avec environ 20% des sols échantillonnés lui correspondant. Le sol le moins représenté est le sol 15 qui a un pourcentage de représentation de l'ordre de $10^{-4}$.

### Relations entre X & Y

Première estimation des relations possibles entre les variables quantitatives explicatives et la variable réponse.

```{r dataCov, include=TRUE, fig.height=3, fig.width=8}
# variables X quantitatives
par(mfrow=c(1,2))
for (i in 1:10) {
  boxplot(Xforest[,i]~Cov_type,ylab=colnames(Xforest)[i],xlab = "Cover type")
}


# variables X qualitatives
temp_forest <- Xforest
temp_forest[,11:54][temp_forest[,11:54] == 0] <- NA

temp_forest <- pivot_longer(temp_forest,cols = seq(15,54),names_to = "Soil_type",values_to = "pres_abs", values_drop_na = TRUE)
#moche mais fonctionne
temp_forest <- pivot_longer(temp_forest,cols = seq(11,14),names_to = "Wilderness_area",values_to = "pres_ab", values_drop_na = TRUE)
temp_forest <- temp_forest[,-c(12,14)]

# par(mfrow=c(1,1))
# mosaicplot(Cov_type~temp_forest$Soil_type
#            ,main="relation Cover type & Soil type")
# 
# mosaicplot(Cov_type~temp_forest$Wilderness_area
#            ,main="relation Cover type & Wilderness area")
# 
#MOCHE
```

Sans analyses plus poussées on ne peut que faire des hypothèses sur les variables impactant Y. Ainsi, l'altitude semble jouer un rôle important pour discriminer les différents types de couvert végétal. 

### Analyse des interactions entre les variables X

```{r}


# Interactions possibles entre between les variables qualitatives
table(temp_forest$Wilderness_area,temp_forest$Soil_type)
################################
# JCP SI ON EN DEDUIT QQCH ????
#################################

# Interactions possibles entre les variables qualitatives et quantitatives

for (i in 1:10) {
  par(mfrow=c(1,2))
  boxplot(temp_forest[,i]~temp_forest$Wilderness_area, varwidth = TRUE, ylab = colnames(temp_forest)[i], xlab = "Wilderness area", main = "", xaxt = "n")
 boxplot(temp_forest[,i]~temp_forest$Soil_type, varwidth = TRUE, ylab = colnames(temp_forest)[i], xlab = "Soil type ", main = "", xaxt = "n")
}


```


Interactions between qualitative X and quantitative + orhtogonality of the plan studied in another file to avoid importing multiple datasets every time 

Interactions potentielles :  \
- Horizontal distance to fire, Wilderness area  
- Horizontal distance to Roadway, Wilderness area  
- Slope, Wilderness area  
- Slope, soil type  
- Elevation, Wilderness area  

### Analyse des corrélations entre les X quantitatifs

```{r}
M<-cor(Xforest[,1:10])
corrplot.mixed(M,upper="square",lower.col="black", tl.col="black",cl.cex = 0.7,tl.cex = 0.6,number.cex =0.7)
Xforest_red <- Xforest[,-9]
```

L'ombre à 3h est corrélée avec un coefficient r=-0.78 avec l'ombre à 9h. Si on prend un seuil à 0.7 on retire cette l'ombre à 3h arbitrairement.

### Centrer et réduire les variables quantitatives

```{r}
Xforest_red_cr <- Xforest_red
Xforest_red_cr[1:9] <- apply(Xforest_red_cr[1:9],MARGIN = 2,function(X) scale(X,center = TRUE, scale = TRUE))
```


## Modèle

- Le modèle linéaire ne peut pas tourner sur 387341 données, donc on fait plusieurs fois tourner sur environ 7000 données. Dans l'idéal on le fait tourner environ 550 fois pour que le total des données d'entraînement représente environ 2/3 des données. \
   
- Le plan n'est pas orthogonal, on n'utilise pas d'interactions ou alors on en utilise mais on fait attention aux paramètres des interactions (Beta) qui peuvent être moins fiables surtout sur les modalités rares dans l'interprétation (en calculant la variance des Beta pour un ensemble de modèles crées). \
  
- On sélectionne les variables en ajouttant une pénalité lasso au modèle. 
  
- Pour tester la qualité du modèle on s'intéresse à l'accuracy moyenne, soit le nombre moyen de cover types correctement prédits sur l'ensemble des modèles simulés divisé par le nombre total de cover type testé.


### Ecriture du modèle

On utilise une fonction qui calcule automatiquement la valeur du tuning parameter pour la pénalité lasso

```{r fullmodel,include=TRUE}


rep <- 10 #normalement sur 550 essais mais tournerait environ 36 heures
L_coeffs <- list()
accuracy <- matrix(NA,nrow = rep,ncol = 15)


T1<-Sys.time()
for (b in 1:rep) { 
  # subset de données 
  set.seed(b)
  select_indiv <- part_data(forest)
  Ytrain <- Cov_type[select_indiv[[1]]] 
  Ytest <- Cov_type[select_indiv[[2]]] 
  Xtrain <- Xforest_red_cr[select_indiv[[1]],] 
  Xtest <- Xforest_red_cr[select_indiv[[2]],]
  
  # Introduction des interactions dans le modèle
  f <- as.formula(Ytrain ~ .+Wilderness_Area_1:Elevation+
                    Wilderness_Area_2:Elevation+
                    Wilderness_Area_3:Elevation+
                    Wilderness_Area_4:Elevation+
                    Wilderness_Area_1:Slope+
                    Wilderness_Area_2:Slope+
                    Wilderness_Area_3:Slope+
                    Wilderness_Area_4:Slope+
                    Wilderness_Area_1:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_2:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_3:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_4:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_1:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_2:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_3:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_4:Horizontal_Distance_To_Roadways,
                  cbind(Xtrain,Ytrain))
  
  f2 <- as.formula(Ytest ~ .+Wilderness_Area_1:Elevation+
                    Wilderness_Area_2:Elevation+
                    Wilderness_Area_3:Elevation+
                    Wilderness_Area_4:Elevation+
                    Wilderness_Area_1:Slope+
                    Wilderness_Area_2:Slope+
                    Wilderness_Area_3:Slope+
                    Wilderness_Area_4:Slope+
                    Wilderness_Area_1:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_2:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_3:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_4:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_1:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_2:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_3:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_4:Horizontal_Distance_To_Roadways,
                  cbind(Xtest,Ytest))
  
  Xtrain_inter <- model.matrix(f, cbind(Xtrain,Ytrain))[, -1]
  Xtest_inter <- model.matrix(f2, cbind(Xtest,Ytest))[, -1]
  # formulation du modèle avec une pénalité lasso
  
  #Xtrain <- matrix(as.numeric(as.matrix(Xtrain)),nrow = nrow(Xtrain)) #pour un modèle sans intéractions
  mod <- cv.glmnet(Xtrain_inter,Ytrain, alpha=1,family = "multinomial")
  L_coeffs[[b]] <- coef(mod, s = "lambda.min") #on choisit la pénalité lasso optimale pour le modèle basé sur 
  
  # prédictions du modèle
  ychap <- predict(mod, Xtest_inter,type = "class",s = "lambda.min")
  
  #le modèle fai-il de bonne predictions
  acc <- 100*length(which(ychap == Ytest))/3560#on compte le nombre de fois où l'algorithme prédit le bon cover type
  
  for (i in 1:7) {
    acc<- c(acc,
            100*length(which(ychap == Ytest & Ytest == i))/length(which(ychap == i)),
            100*length(which(ychap == Ytest & Ytest == i))/length(which(Ytest == i)))
    
  }
  accuracy[b,] <- acc

}

T2<-Sys.time()

(Tdiff= difftime(T2, T1))


```
Plusieurs difficultés ont été rencontrées lors de cette étape: \
1- Comment choisir la pénalité lasso: test avec l'AIC, le BIC, otimisation par R basée sur ... \
2- Combien d'intéractions intégrer dans le modèle, plus il y avait d'intéractions, plus le temps de calcul augmentait. Nous avons sélectionnées quelques interactions en exemple \
3- Commment faire l'échantillonnage 



Calculer le pourcentage de bonne prédiction moyen par les modèle entrainés sur différents jeux de données d'entrainement, premiere colonne pour l'ensemble des données, puis pourcentage de 1 prédits qui étaient vraiment des 1  et le pourcentage 1 prédits parmis toutes les valeurs où 1 devait etre prédit

```{r}
res <- matrix(apply(accuracy,2,mean),nrow = 1)
colnames(res) <- c("mean_accuracy","cov_type1a","cov_type1b","cov_type2a","cov_type2b","cov_type3a","cov_type3b","cov_type4a","cov_type4b","cov_type5a","cov_type5b","cov_type6a","cov_type6b","cov_type7a","cov_type7b")
res
```

Malgrès que des classes soient très peu représentés dans le jeu de donnée, en équilibrant l'échantillonnage, on peut voir que ces classes sont tout de même prédites dans le modèle. Mais le problème est qu'elles sont sur-représentées dans les sorties du modèle. Par exemple le modèle a détecté correctement 77.7% des cover-type 4 qui était dans le jeu de données d'entrainement. Cependant seulement 15% des individus prédits dans le cover type 4 étaient corrects, cela signifie que de trop d'individus ont été classé dans le type 4. Ce constat vaut pour les classes 5,6 et 7 qui sont toutes plutôt rares.


On regarde les variables qui ressortent moins de 80% des fois

```{r}
occurence_var <- matrix(0,nrow = 54,ncol=7) # contient en ligne la somme des coefficients Beta non nuls au cours des répétitions du modele pour chaque classe en colonne

for (i in 1:rep) {
  for (j in 1:7) {
    occurence_var[(which(L_coeffs[[i]][[j]] != 0)),j] <- (occurence_var[(which(L_coeffs[[i]][[j]] != 0)),j]+ 1)
  }
  
}
#quelles variables ne sont pas présentes plus de 80% des fois ? 
occurence_var_pourcent <- apply(occurence_var, c(1,2), function(X) X*100/rep)
occurence_inf80 <- list()
for (i in 1:7) {
  occurence_inf80[[i]] <- c("intercept",colnames(Cov_red))[which(occurence_var_pourcent[,i]<80)]
  print(occurence_inf80[[i]])
}


```

En plus de la variable ombre à 3 heures.




