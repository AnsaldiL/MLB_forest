---
title: "Cover_Type"
author: "Lucia, Lucile et Youna"
date: "2023-11-03"
output: html_document
---

# Introduction et présentation des données
## Problématisation

## Importation et formatage des données

Importation des library nécessaires
```{r, echo=false}
library(tidyverse)
library(dplyr)
library(FactoMineR)
library(ggplot2)
library(class)
library(ggplot2) 
library(corrplot)
library(glmnet) # multinomiale avec pénalité lasso
library(rpart)
library(partykit)
#library(caret)
library(randomForest)
library(randomForestExplainer)
```

Importation des données et modification des noms de colonnes.
```{r}
forest= read.table(file = "covtype.data", sep=",", header=TRUE) 

a <- rep("Soil_Type_",40)
for (i in 1:40) {
  a[i]<-paste0(a[i],as.character(i))
} 

name <- c("Elevation",
          "Aspect",
          "Slope",
          "Horizontal_Distance_To_Hydrology",
          "Vertical_Distance_To_Hydrology",
          "Horizontal_Distance_To_Roadways",
          "Hillshade_9am",
          "Hillshade_Noon",
          "Hillshade_3pm",
          "Horizontal_Distance_To_Fire_Points",
          "Wilderness_Area_1",
          "Wilderness_Area_2",
          "Wilderness_Area_3",
          "Wilderness_Area_4",
          a,
          "Cover_Type")

colnames(forest)<- name
```

Extraction des labels à prédire pour les apprentissages supervisés. Les labels sont stockés dans Cov_type. Xforest est le jeu de donné initial auquel est enlevé la colonne des labels.

```{r}
Cov_type = forest$Cover_Type
Xforest <- subset(forest, select = -Cover_Type)
```

Réduction des dimensions avec une PCA. Seul le premier plan est conservé pourles analyses nécessitant une réduction de dimension. 
```{r}
pcaXforest <- PCA(Xforest, ncp = 2) 
```

## Vérification des données

### Généralités

```{r}
#str(forest)
table(is.na(forest))
```
Il n'y a pas de valeurs manquantes et les variables sont au bon format:  
- factor pour les variables qualitatives,  
- int pour les variables quantitatives 

### Valeurs extremes de $X$ 

```{r dataCov1, include=TRUE}
par(mfrow=c(2,3))
for (i in 1:10) {
  # Cleveland plot
  boxplot(forest[,i],pch=16,col='salmon',xlab=colnames(forest)[i])
}

```

Les points sans ombre à 9 heures ne sont pas les mêmes que ceux à 12 heures, les valeurs paraissent cohérentes.Les autres valeurs semblent plausibles.


### Répartition des individus pour les variables qualitatives 

```{r}
quali <- apply(forest[,11:54], MARGIN = 2, table)
print(as.data.frame(round(100*quali[2,]/(quali[1,]+quali[2,]),digits = 2),optional = TRUE ))
```

En calculant le pourcentage des observations appartenant à chaque classe de "Wilderness area" et de "Soil type, on remarque que Wilderness area 2 et 4 ne représentent respectivement que 5.1 et 6.4 % des observations.\
\

Pour les types de sols, on remarque que la plupart sont assez peu représentés avec un pourcentage de représentation de l'ordre de $10^{-1}$ ou $10^{0}$. Le type de sol numero 29 est particulièrement représenté avec environ 20% des sols échantillonnés lui correspondant. Le sol le moins représenté est le sol 15 qui a un pourcentage de représentation de l'ordre de $10^{-4}$.

### Relations entre X & Y 

Première estimation des relations possibles entre les variables quantitatives explicatives et la variable réponse.

```{r dataCov2, include=TRUE, fig.height=3, fig.width=8}
# variables X quantitatives
par(mfrow=c(1,2))
for (i in 1:10) {
  boxplot(Xforest[,i]~Cov_type,ylab=colnames(Xforest)[i],xlab = "Cover type")
}

```

Sans analyses plus poussées on ne peut que faire des hypothèses sur les variables impactant Y. Ainsi, l'altitude semble jouer un rôle important pour discriminer les différents types de couvert végétal.

# Implémentation des algorithmes de machine learning
## Data driven algorithms

### Unsupervised

#### Algorithme des k-means
##### Principe de la méthode
La méthode des k-means est un clustering selon les similarité des individus au sein du groupe et des différence des individus d'autres groupes. Un idividu est affecté à un nouveau groupe s'il est plus proche de la moyenne de ce nouveau groupe que de la moyenne de son groupe initial. Les moyennes sont mise-à-jour à chaque itération.

Il faut initialement déterminer le nombre de groupes attendu. Ici, c'est le nombre de couverts forestiers possibles.

##### Algorithme des k-means pour prédire le type de couverture forestière 
```{r}
n_clusters = length(unique(Cov_type)) # Nombre de cluster attendu : autant que de couverts forestiers possibles
set.seed(1)
i.centers = sample(1:dim(pcaXforest$ind$coord)[1],n_clusters) # initialisation aléatoire des clusters. 
centers = pcaXforest$ind$coord[i.centers,]
km = kmeans(pcaXforest$ind$coord,centers,nstart=10,iter.max=50) # avec 10 sets aléatoires et 50 itérations au maximum
cl = km$cluster # tous les individus sont associés à une classe

cl_lab = cl
for (k in 1:n_clusters){
  ii = which(cl==k) 
  counts=table(Cov_type[ii]) # Nb d'occurences de chaque classe
  imax=which.max(counts) # Calcul de la classe majoritaire
  maj_lab=attributes(counts)$dimnames[[1]][imax] # attribution de l'étiquette de la classe
  print(paste("Classe ",k,", label majoritaire = ",maj_lab))
  cl_lab[ii] = maj_lab
}

#matrice de confusion et accuracy
confusion = (conf_mat = table(Cov_type,cl_lab, dnn=list("Observed","Predicted")))
print(confusion)
accuracy <- sum(cl_lab == Cov_type)/(length(Cov_type))
print(paste("l'accuracy de la classification avec l'algorithme des k-means est de",accuracy)) #0.5507693

# représentation de la matrice de confusion
df = as.data.frame(confusion)
df %>% 
  ggplot( aes(x = Observed, y = Predicted, fill = Freq))+
  geom_tile()+
  geom_text(aes(label = round(Freq, 1))) +
  scale_fill_gradient(low="#FFFF88",high="#FF0000")+
  coord_fixed()+
  theme_minimal()+
  theme(axis.text = element_text(size = 12))+
  theme(axis.title = element_text(size = 14)) 

```

L'accuracy est acceptable, plus de la moitié des couverts forestiers sont bien prédit. Néanmoins, La seule classe correctement prédite est la classe 2. Cela n'est pas étonnant car il s'agit d'une classe très majoritaire. Les classes 1, 2 et 3 sont les seules que l'algorithme parvient à proposer, encore une fois, cela est du au très faible nombre d'individus des classes 4 à 7, comme présenté dans l'histogramme ci-dessous :

```{r}
hist(Cov_type, col="yellow3")
```

Finalement, l'algorithme n'a pas su former des groupes correspondant aux Cover types car, dans chaques groupe, les classes 1, 2 et 3 sont majoritaire, du fait de leur sur-représentation.

### Supervised

Pour les apprentissages supervisés, il s'agit de commencer l'analyse en séprant le jeu de donné en deux set, train et test, pour d'abord entrainer l'algorithme puis l'évaluer sur des données différentes. La valeur choisie est généralement 2/3 de train et 1/3 de test. Pour comparer avec la méthode model driven, un partiotionnement particulier a été réalisé sur une plus faible partie du jeu de donnée.

Voici la fonction de partitionnement implémentée :

```{r}
part_data <- function(data,freq = rep(1/7,7)){
  # prend en entree le jeu de donnee à echantillonner et un vecteur de fréquences pour chaque classe dans l'ordre (1 à 7)
  # valeur par défaut, toutes les classes sont échantillonnées à peu près à la meme fréquence
  # renvoie les indices des individus de l'echantillon d'entrainement et de l'echantillon de validation
  nb_indiv <- length(data[,1])
  itrain <- c()
  itest <- c(1:nb_indiv)
  # on force l'echantillon d'entrainement à avoir au moins 3 observations par type de sol
  for (i in 15:54) { #les colonnes 14 à 53 sont les colonnes "soil type"
    itrain <- c(itrain,sample(x = which(data[,i] == 1 ),size = 3)) 
  }
  
  # on force l'echantillon d'entrainement à avoir au moins 3 observations par type de sol
  for (i in 11:14) { #les colonnes" 14 à 53 sont les colonnes "soil type""Wilderness_area"
    itrain <- c(itrain,sample(x = setdiff(which(data[,i] == 1 ),itrain),size = 3)) #dans les données pas deja echantilonnee 
  }
  
  # on force l'echantillon d'entrainement à avoir au moins 1000 observations par type de recouvrement végétal
  nb <- freq*7000
  for (i in 1:7) {
    itrain <- c(itrain,sample(x = setdiff(which(data$Cover_Type == i),itrain),size = nb[i]))
  }
  
  itest <- setdiff(itest,itrain)
  itest <- sample(itest,3560) 
  
  return(list(itrain,itest))

}


#Fréquence de chaque classe
table(forest$Cov_Type)
freq_cover <- table(forest$Cov_Type)/length(forest$Cov_Type) # en proportions
```

#### Algorithme des k-nearest neighbourgs
##### Principe de la méthode

La méthode des K-NN consiste à réaliser une moyenne entre les individus voisins pour estimer la variable d'interet. Le nombre optimal de voisin doit être identifié car l'algorithme est sensible à ce choix. Comme il s'agit de classification, la réponse est estimée au vote majoritaire afin de prédire la classe.

##### Algorithme des k-nearest neighbourgs pour prédire une couverture forestière, avec le partitionnement présenté

Recherche du meilleur nombre de voisins :
```{r}
#on travaille sur la dimention réduite avec l'objet pcaXforest
C = factor(Cov_type,levels=c(1,2,3,4,5,6,7)) 
nb_Cov_type <- length(unique(Cov_type))

# on va trouver le meilleur nombre de voisin possible pour minimiser l'erreur
nb_neighbors = c(1,5,10,20,25,30,35,40)

n = dim(pcaXforest$ind$coord)[1]
B = 10
err_knn = matrix(0,B,length(nb_neighbors))


for (b in 1:B) { #10 répétitions du modèle 
  set.seed(b)
  
  itrain <- unlist(part_data(forest)[1])
  itest <- unlist(part_data(forest)[2])
  
  
  Xs_train = scale(pcaXforest$ind$coord[itrain,])
  Xs_test = scale(pcaXforest$ind$coord[itest,],center=apply(pcaXforest$ind$coord[itrain,],2,mean),scale=apply(pcaXforest$ind$coord[itrain,],2,sd))
  for (i in 1:length(nb_neighbors)) {
    knn_res = knn(Xs_train,Xs_test,Cov_type[itrain],k=nb_neighbors[i],prob=TRUE)
    err_knn[b,i] = sum(Cov_type[itest]!=knn_res)/length(itest)
  }
  
}

apply(err_knn,2,mean) #on fait la moyenne des col de err_knn 
colnames(err_knn)=nb_neighbors
boxplot(err_knn) 
w = which.min(apply(err_knn,2,mean)) #le meilleur nombre de voisins
print(paste("le nombre de voisins optimal est",nb_neighbors[w]))
```
  
  
Application de l'algorithme aux données avec le nombre de voisins optimal

```{r}
w = which.min(apply(err_knn,2,mean)) #le meilleur nombre de voisins

n = dim(pcaXforest$ind$coord)[1]
B = 10 # number of samples for the cross validation
y_test = y_prob = NULL
for (b in 1:B){
  set.seed(b)
  
  itrain <- unlist(part_data(forest)[1])
  itest <- unlist(part_data(forest)[2])
  
  Xs_train = scale(pcaXforest$ind$coord[itrain,])
  Xs_test = scale(pcaXforest$ind$coord[itest,],center=apply(pcaXforest$ind$coord[itrain,],2,mean),scale=apply(pcaXforest$ind$coord[itrain,],2,sd))
  knn_res = knn(Xs_train,Xs_test,C[itrain],k=nb_neighbors[w],prob=TRUE)
  y_prob = c(y_prob,attributes(knn_res)$prob)
  y_test = c(y_test,C[itest])
}

#multiclass.roc(y_test, y_prob, level = 7, plot=TRUE) #interet de la courbe ROC..?

Cres <- C[itest]

conf_mat_knn = (conf_mat = table(Cres, knn_res, dnn=list("Predicted", "Observed")))
print(conf_mat_knn)

accuracy <- sum(knn_res == Cres)/(length(Cres))
print(accuracy)
#0.3579832

# représentation de la matrice de confusion
df = as.data.frame(conf_mat_knn)
df %>% 
  ggplot( aes(x = Observed, y = Predicted, fill = Freq))+
  geom_tile()+
  geom_text(aes(label = round(Freq, 1))) +
  scale_fill_gradient(low="#FFFF88",high="#FF0000")+
  coord_fixed()+
  theme_minimal()+
  theme(axis.text = element_text(size = 12))+
  theme(axis.title = element_text(size = 14)) 
```

##### Algorithme des k-nearest neighbourgs pour prédire une couverture forestière, avec le partitionnement 2/3 et 1/3

Application de l'algorithme aux données avec le nombre de voisins optimal. Cette fois, l'ensemble du jeu de données est utilisé.

```{r}
w = which.min(apply(err_knn,2,mean)) #le meilleur nombre de voisins

n = dim(pcaXforest$ind$coord)[1]
B = 1 # number of samples for the cross validation
y_test = y_prob = NULL
for (b in 1:B){
  set.seed(b)
  
  itrain <- sample(c(1:nrow(forest)), round((2/3)*n))
  itest <- setdiff(c(1:nrow(forest)), itrain)
  
  Xs_train = scale(pcaXforest$ind$coord[itrain,])
  Xs_test = scale(pcaXforest$ind$coord[itest,],center=apply(pcaXforest$ind$coord[itrain,],2,mean),scale=apply(pcaXforest$ind$coord[itrain,],2,sd))
  knn_res = knn(Xs_train,Xs_test,C[itrain],k=25, prob=TRUE)#nb_neighbors[w],prob=TRUE)
  y_prob = c(y_prob,attributes(knn_res)$prob)
  y_test = c(y_test,C[itest])
}


Cres <- C[itest]

conf_mat_knn = (conf_mat = table(Cres, knn_res))
print(conf_mat_knn)

accuracy <- sum(knn_res == Cres)/(length(Cres))
print(accuracy)
#0.5693757 with B= 1

df = as.data.frame(conf_mat_knn)
df %>% 
  ggplot( aes(x = Observed, y = Predicted, fill = Freq))+
  geom_tile()+
  geom_text(aes(label = round(Freq, 1))) +
  scale_fill_gradient(low="#FFFF88",high="#FF0000")+
  coord_fixed()+
  theme_minimal()+
  theme(axis.text = element_text(size = 12))+
  theme(axis.title = element_text(size = 14)) 

```

Le résultat est meilleur lorsque l'ensemble du jeu de donnée est utilisé et est séparé en 2/3 de train et 1/3 de test. En effet, il s'agit d'une méthode datadriven, la solution doit donc "émerger" des données et pour celà, les données doivent être en quantité.
Seules les classes 1 et 2 sont bien prédites, soit les classes les plus représentées. 
La méthode n'est pas très efficace : accuracy de 0.36 avec le partionnement proposé et 0.57 avec les tiers. Cela s'explique par le grand déséquilibre dans les données et la sous-représentation de certaines classes par rapport aux autres.

# Methodes model-driven

La méthode model-driven étudiée est le modèle multinomial.

## Formalisme du modèle multinomial:

$$ Cover \: type \: \sim \: Elevation \: + \: Aspect \: + \: Slope \: + \: ... \: + \: Soil \: type \: 40 \: + \: Interactions$$

$Y = Cover \: type$, la variable réponse\
$Xs$ les variables prédictives\

## Analyse des interactions entre les variables X

Pour estimer quelles intéractions sont à inclure dans le modèle, on peut représenter les variables quantitatives X en fonction des variables X qualitatives

```{r}
# variables X qualitatives
temp_forest <- Xforest
temp_forest[,11:54][temp_forest[,11:54] == 0] <- NA

temp_forest <- pivot_longer(temp_forest,cols = seq(15,54),names_to = "Soil_type",values_to = "pres_abs", values_drop_na = TRUE)
#moche mais fonctionne
temp_forest <- pivot_longer(temp_forest,cols = seq(11,14),names_to = "Wilderness_area",values_to = "pres_ab", values_drop_na = TRUE)
temp_forest <- temp_forest[,-c(12,14)]

# Interactions possibles entre les variables qualitatives et quantitatives

for (i in 1:10) {
  par(mfrow=c(1,2))
  boxplot(temp_forest[,i]~temp_forest$Wilderness_area, varwidth = TRUE, ylab = colnames(temp_forest)[i], xlab = "Wilderness area", main = "", xaxt = "n")
 boxplot(temp_forest[,i]~temp_forest$Soil_type, varwidth = TRUE, ylab = colnames(temp_forest)[i], xlab = "Soil type ", main = "", xaxt = "n")
}

rm(temp_forest)


```


Interactions potentielles :\
- Horizontal distance to fire, Wilderness area\
- Horizontal distance to Roadway, Wilderness area\
- Slope, Wilderness area\
- Slope, soil type\
- Elevation, Wilderness area

## Analyse des corrélations entre les X quantitatifs

Les modèles linéaire généralisés sont sensibles aux variables explicatives trop correlées entre elles, il faut donc vérifier les corrélations.

```{r}
M<-cor(Xforest[,1:10])
corrplot.mixed(M,upper="square",lower.col="black", tl.col="black",cl.cex = 0.7,tl.cex = 0.6,number.cex =0.7)
Xforest_red <- Xforest[,-9]
```

L'ombre à 3h est corrélée avec un coefficient r=-0.78 avec l'ombre à 9h. Si on prend un seuil à 0.7 on retire cette l'ombre à 3h arbitrairement.

## Centrer et réduire les variables quantitatives

```{r}
Xforest_red_cr <- Xforest_red
Xforest_red_cr[1:9] <- apply(Xforest_red_cr[1:9],MARGIN = 2,function(X) scale(X,center = TRUE, scale = TRUE))
```

## Modèle

-   Le modèle linéaire ne peut pas tourner sur 387341 données, donc on fait plusieurs fois tourner sur environ 4000 données. Dans l'idéal on le fait tourner environ &àà fois pour que le total des données d'entraînement représente environ 2/3 des données. Dans la pratique, on ne le fait tourner que dix fois car la puissance de nos ordinateurs est trop faible. \

-   Le plan n'est pas orthogonal, il est alors difficile d'utiliser d'interactions. On en utilise mais on fait attention aux coefficients prédits pour les interactions (Beta) qui peuvent être moins fiables surtout sur les modalités rares.\

-   On sélectionne les variables en ajouttant une pénalité lasso au modèle.

-   Pour tester la qualité du modèle on s'intéresse à l'accuracy moyenne, soit le nombre moyen de cover types correctement prédits sur l'ensemble des modèles simulés divisé par le nombre total de cover type testé.

## Ecriture du modèle

On utilise une fonction qui optimize automatiquement la valeur du tuning parameter pour la pénalité lasso.

```{r fullmodel,include=TRUE}


rep <- 10 #normalement sur 550 essais mais tournerait trop longtemps
L_coeffs <- list()
prediction <- matrix(NA,nrow = 2066,ncol = rep*2)


T1<-Sys.time()
for (b in 1:rep) { 
  # subset de données 
  set.seed(b)
  select_indiv <- part_data(forest,freq_cover)
  Ytrain <- Cov_type[select_indiv[[1]]] 
  Ytest <- Cov_type[select_indiv[[2]]] 
  Xtrain <- Xforest_red_cr[select_indiv[[1]],] 
  Xtest <- Xforest_red_cr[select_indiv[[2]],]
  
  # Introduction des interactions dans le modèle
  f <- as.formula(Ytrain ~ .+Wilderness_Area_1:Elevation+
                    Wilderness_Area_2:Elevation+
                    Wilderness_Area_3:Elevation+
                    Wilderness_Area_4:Elevation+
                    Wilderness_Area_1:Slope+
                    Wilderness_Area_2:Slope+
                    Wilderness_Area_3:Slope+
                    Wilderness_Area_4:Slope+
                    Wilderness_Area_1:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_2:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_3:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_4:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_1:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_2:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_3:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_4:Horizontal_Distance_To_Roadways,
                  cbind(Xtrain,Ytrain))
  
  f2 <- as.formula(Ytest ~ .+Wilderness_Area_1:Elevation+
                    Wilderness_Area_2:Elevation+
                    Wilderness_Area_3:Elevation+
                    Wilderness_Area_4:Elevation+
                    Wilderness_Area_1:Slope+
                    Wilderness_Area_2:Slope+
                    Wilderness_Area_3:Slope+
                    Wilderness_Area_4:Slope+
                    Wilderness_Area_1:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_2:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_3:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_4:Horizontal_Distance_To_Fire_Points+
                    Wilderness_Area_1:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_2:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_3:Horizontal_Distance_To_Roadways+
                    Wilderness_Area_4:Horizontal_Distance_To_Roadways,
                  cbind(Xtest,Ytest))
  
  Xtrain_inter <- model.matrix(f, cbind(Xtrain,Ytrain))[, -1]
  Xtest_inter <- model.matrix(f2, cbind(Xtest,Ytest))[, -1]
  # formulation du modèle avec une pénalité lasso
  
  #Xtrain <- matrix(as.numeric(as.matrix(Xtrain)),nrow = nrow(Xtrain)) #pour un modèle sans intéractions
  mod <- cv.glmnet(Xtrain_inter,Ytrain, alpha=1,family = "multinomial")
  L_coeffs[[b]] <- coef(mod, s = "lambda.min") #on choisit la pénalité lasso optimale pour le modèle basé sur 
  
  # prédictions du modèle
  prediction[,b] <- predict(mod, Xtest_inter,type = "class",s = "lambda.min")
  prediction[,(rep*2-b+1)] <- Ytest



}

T2<-Sys.time()

(Tdiff= difftime(T2, T1))


```

Plusieurs difficultés ont été rencontrées lors de cette étape: \ 
1- Comment choisir la pénalité lasso: test avec l'AIC, le BIC, otimisation par R. \ 
2- Combien d'intéractions intégrer dans le modèle, plus il y avait d'intéractions, plus le temps de calcul augmentait. Nous avons sélectionnées quelques interactions en guise d'exemple. \ 
3- Comment interpréter les interactions sachant que le plan n'est pas orthogonnal \ 
3- Commment faire l'échantillonnage: devons nous échantillonner le même nombre d'individus dans chaque cover type ou devons nous respecter les fréquences du jeu de donnée total? Après avoir testé les deux méthodes nous avons conservé la seconde car l'accuracy étaient bien meilleurs.


```{r}

df_mod <- matrix(c(rep(seq(1,7),7),
                   rep(1,7),
                   rep(2,7),
                   rep(3,7),
                   rep(4,7),
                   rep(5,7),
                   rep(6,7),
                   rep(7,7),rep(0,49)),byrow = FALSE,nrow = 49,ncol = 3)
df_mod <- as.data.frame(df_mod)
colnames(df_mod) <- c("Observed","Predicted","Freq")

confusion_mod <- NA
accuracy_mod <- c()

for (i in 1:rep) {
  mean_accuracy <- 0
  
  confusion_mod = as.data.frame((conf_mat = table(prediction[,((rep*2)-i+1)],prediction[,i], dnn=list("Observed","Predicted"))))
  confusion_mod$Observed <- as.numeric(confusion_mod$Observed)
  confusion_mod$Predicted <- as.numeric(confusion_mod$Predicted)
  for (j in 1:max(confusion_mod$Observed)) {
    for (k in 1:max(confusion_mod$Predicted)) {
      df_mod[df_mod$Observed == j & df_mod$Predicted == k,3] <- df_mod[df_mod$Observed == j & df_mod$Predicted == k,3]+ confusion_mod[confusion_mod$Observed == j & confusion_mod$Predicted == k,3]
      df_mod <- as.data.frame(df_mod)
    }
    #calcul de l'accuracy
    mean_accuracy <- mean_accuracy + confusion_mod[confusion_mod$Observed==j & confusion_mod$Predicted==j,3]
    }
    accuracy_mod<-c(accuracy_mod,mean_accuracy/2066)
    
  
}
df_mod_pourc<-df_mod
df_mod_pourc$Freq <-df_mod_pourc$Freq/rep
  
ggplot(df_mod_pourc, aes(x = Observed, y = Predicted, fill = Freq))+
  geom_tile()+
  geom_text(aes(label = round(Freq, 1))) +
  scale_fill_gradient(low="#FFFF88",high="red")+
  coord_fixed()+
  theme_minimal()+ggtitle("Matrice de confusion moyenne modèle multinomiale")+
  theme(axis.text = element_text(size = 12))+
  theme(axis.title = element_text(size = 14))+
  theme(plot.title = element_text(hjust = 0.5))




print(paste("Sur dix répétitions, l'accuracy est de :", mean(accuracy_mod)," et d'écart type, ", sd(accuracy_mod)))



```

Il semble y avoir beaucoup de confusion entre les classes 1,2 et 7. La classe 3 est plutôt bien prédite. Les classes les plus rares sont mal prédites: 4 est assignée à de nombreuses autres classes, 5 est assignée à la classe 2 et 6 aux classes 2 et 3. 

Lorsque l'échantillonnage imposait un nombre d'individus identique pour chaque type de couverture, on observait une sur-prédiction des classes rares.

On regarde les variables qui ressortent moins de 80% des fois

```{r}
occurence_var <- matrix(0,nrow = 70,ncol=7) # contient en ligne la somme des coefficients Beta non nuls au cours des répétitions du modele pour chaque classe en colonne

for (i in 1:rep) {
  for (j in 1:7) {
    occurence_var[(which(L_coeffs[[i]][[j]] != 0)),j] <- (occurence_var[(which(L_coeffs[[i]][[j]] != 0)),j]+ 1)
  }
  
}
#quelles variables ne sont pas présentes plus de 80% des fois ? 
occurence_var_pourcent <- apply(occurence_var, c(1,2), function(X) X*100/rep)
occurence_inf80 <- list()
for (i in 1:7) {
  occurence_inf80[[i]] <- c("intercept",row.names(L_coeffs[[1]]$`1`))[which(occurence_var_pourcent[,i]<80)]
}


```


![](\selectvar.png)

Représentées en bleu, les variables qui entrent en compte dans la prédiction des types de couvertures (de 1 à 7) au  moins 80% des fois, en rouge les autres. La colonne de droite correspond aux variables utilisées dans l'algorithme de random forest, en rouge celle dont la contribution est < à XXX et en bleu celle dont elle est supérieure à XXX. Les variables en plus claires représentent les variables propres à la régression linéaire soit: les interactions et l'intercept. \ 
  
  

Pour le modèle linéaire, les variables semblent quasiment toutes jouer un rôle dans la prédiction d'au moins une des classes, excepté les variables de type de sol 26 et 28, et l'interaction entre Horizontal distance to roadway et wilderness area?. Sans oublier la variable ombre à 3 heures retirée précedemment.  
Trois variables ont de l'importance pour au moins 5 des type de couvert: horizontal distance to roadway, ainse que les intéractions elevation:wilderness area 2 et horizontal distance to roadway: wilderness area 4. \ 

On ne remarque pas de motif particulier dans les variables importantes et pas de similitude avec les variables sélectionnées par le random forest.



## Attention à l'interprétation des coefficients d'intéractions

Pour les deux intéractions importantes, on regarde si les coefficients varient selon les simulations. On fait attention à cela notamment parce que le plan n'est pas orthognoal

```{r}
el_wa <- matrix(NA,nrow = rep,ncol = 7)
hdt_wa <- matrix(NA,nrow = rep,ncol = 7)
for (i in 1:10) {
  for (j in 1:7) {
    el_wa[i,j] <- L_coeffs[[i]][[j]][56] #coefficient de l'interaction elevation, wilderness area 2
    hdt_wa[i,j] <- L_coeffs[[i]][[j]][70] #coefficient de l'interaction horizontal distance to roadway, wilderness area 4
  }
  
}

interactions <- cbind(apply(el_wa,MARGIN = 2, mean),
      apply(el_wa,MARGIN = 2, sd),
      apply(hdt_wa,MARGIN = 2, mean),
      apply(hdt_wa,MARGIN = 2, sd))

colnames(interactions)<- c("moyenne Elevation:W area 2","ecart type Elevation:W area","moyenne Distance to roadway:W area 4","ecart type Distance to roadway:W area 4")

row.names(interactions)<- c("Cover type 1","Cover type 2","Cover type 3","Cover type 4","Cover type 5","Cover type 6","Cover type 7")

print(interactions)

```

Les écarts types des coefficients entre chaque simulations sont très grands, il devent donc difficile d'interpréter ces coefficients

# Comparaison des méthodes et conclusion


| Méthode       | Accurracy   | Remarques                                  |
|---------------|-------------|--------------------------------------------|
| K-means       | 0.55        | Toutes les classes ne sont pas prédites... |
| K-NN          | 0.37 à 0.57 | Résulats moyens                            |
| Multinomial model | 0.72    |                                            |
| Decision tree | 0.72 à 0.87 |                                            |
| Random forest | 0.78 à 0.98 |                                            |

IDEE CONCLU: - Pour les datas driven methods: + de données = + accuracy - Différence KNN- Random forest: la dimension reduction des KNN entraine une perte d'information par rapport au deux autres algo.

