---
title: "Multinomial regression"
author: "Youna"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2) # graph package
library(tinytex) # Pour la sortie pdf
library(corrplot)# Correlation matrix calculus
#library(VGAM)
library("nnet")# multinomiale
```

Idée d'exploration du jeu de données:
Knn et Knn sur variables de PCA
1) data driven:
arbre de décision et généralisation en foret aléatoire (généralement meilleure en prédictions)
2) model driven:
modèle linéaire généralisé sur le réseau de neuronnes



## Import data 
```{r}
setwd("C:/Users/youy0/Desktop/master/S9/MLB/Projet/data")
Cov_type <- read.csv("cov_type_reduit.csv",header = TRUE)
Cov_type <- Cov_type[,-1]
colSums(is.na(Cov_type))
str(Cov_type)
```

Il n'y a pas de NA
On veut faire une multinomiale GLM

### Outliers in $Y$ and distribution of $Y$

As $Y$ is a binary variable, there is no distribution. However, we could inspect how many 0 and 1 we have.

```{r dataY, include=TRUE}
# Number of 0 and 1 in Y
table(Cov_type$Cover_Type)
table(Cov_type$Cover_Type)/length(Cov_type$Cover_Type)
```
Les classes 3, 4, 5, 6, 7 représentent respectivement 6.2, 0.5, 1.6, 3.0 et 3.5 % des données, nous considérons ces classes come étant plutôt rares comparées aux classes 1 et 2 qui représentent à elles deux 85% des données. 

### Outliers in $X$ and distribution of $X$

```{r dataCov, include=TRUE, fig.height=3, fig.width=8}
for (i in 1:10) {
  par(mfrow=c(1,3))
  # Cleveland plot
  dotchart(Cov_type[,i],pch=16,col='blue',xlab=colnames(Cov_type)[i])
  # Histogram
  hist(Cov_type[,i],col='blue',xlab=colnames(Cov_type)[i],main="")
  # Quantile-Quantile plot
  qqnorm(Cov_type[,i],pch=16,col='blue',xlab=colnames(Cov_type)[i])
  qqline(Cov_type[,i],col='red')
}

```

```{r}
table(Cov_type$Soil_type)
table(Cov_type$Wilderness_area)
```

### Relations between X & Y

```{r dataCov, include=TRUE, fig.height=3, fig.width=8}

for (i in 1:10) {
  par(mfrow=c(1,1))
  boxplot(Cov_type[,i]~Cov_type$Cover_Type,ylab=colnames(Cov_type)[i],xlab = "Cover type")
}

```

```{r}
mosaicplot(Cov_type$Soil_type~Cov_type$Cover_Type
           ,main="relationship cover type & soil type")

mosaicplot(Cov_type$Wilderness_area~Cov_type$Cover_Type
           ,main="relationship cover type & soil type")
```



### Analysis of possible interactions between all Xs independent variables

```{r datacolin, include=TRUE, fig.height=4, fig.width=8}
# Checking collinearity between both categorical independent variables
table(Cov_type$Wilderness_area,Cov_type$Soil_type)

# Checking collinearity between categorical and continuous independent variables

for (i in 1:10) {
  par(mfrow=c(1,2))
  boxplot(Cov_type[,i]~Cov_type$Wilderness_area, varwidth = TRUE, ylab = colnames(Cov_type)[i], xlab = "Wilderness area", main = "")
 boxplot(Cov_type[,i]~Cov_type$Soil_type, varwidth = TRUE, ylab = colnames(Cov_type)[i], xlab = "Soil type ", main = "")
}

```
Interactions:  
- Horizontal distance to fire, Wilderness area  
- Horizontal distance to Roadway, Wilderness area  
- Slope, Wilderness area  
- Slope, soil type  
- Elevation, Wilderness area  


```{r}
M<-cor(Cov_type[,1:10])
corrplot.mixed(M,upper="square",lower.col="black", tl.col="black",cl.cex = 0.7,tl.cex = 0.6,number.cex =0.7)
Cov_red <- Cov_type[,-9]
```
Shade at 3 is -0.78 corrélated with shade at 9 I remove it 

Le plan n'est pas orthogonal, on n'utilise pas d'interactions ou alors on en utilise mais on fait attention aux paramètres des interactions (Beta) qui peuvent être moins fiables surtout sur les modalités rares dans l'interprétation -> on peut calculer la variance des Beta pour l'ensemble des modèles crées, on peut trier les variables avec drop1 ou avec la pénalité lasso

- faire nombreux modeles sur peut de données en forcant à avoir tous les cover type (sur 2/3 des données environ)
- calculer la variance de chaque parametre du modèle
- calculer les erreurs moyennes
- tester si il y a des interactions entre les variables
- reprendre premier jeu de données

Le modèle linéaire ne peut pas tourner sur 387341 données, donc on fait plusieurs fois tourner sur 7000

```{r fullmodel,include=TRUE}

i = 1
b=1
err = NULL
err_prob = NULL
L = list()
T1<-Sys.time()
for (b in 1:10) { #550 répétitions du modèle 

  set.seed(b)
  itrain <- c()
  for (i in 1:7) {
    itrain <- c(itrain,sample(x = which(Cov_red$Cover_Type == i),size = 1000))
  }
  for (i in unique(Cov_red$Soil_type)) {
    itrain <- c(itrain,sample(x = which(Cov_red$Soil_type == i ),size = 3)) #forcer pour avoir au moins 3 données de chaque
    #au total on a 7120 données d'entrainement
  
    
  }
  # Model formulation
  mod<-multinom(as.factor(Cover_Type)~ Elevation
        + Slope
        + Aspect
        + Horizontal_Distance_To_Hydrology
        + Vertical_Distance_To_Hydrology
        + Horizontal_Distance_To_Roadways
        + Hillshade_9am
        + Hillshade_Noon
        + Horizontal_Distance_To_Fire_Points
        + Soil_type
        + Wilderness_area
        + Wilderness_area*Slope
        + Wilderness_area*Horizontal_Distance_To_Fire_Points
        + Wilderness_area*Horizontal_Distance_To_Roadways
        + Soil_type*Slope
        ,data=Cov_red[itrain,])
  itest <- setdiff(1:581012,itrain)
  itest <- sample(itest,2380) #on prend 2380 données de test (on a donc environ 9500 données pour chaque experience avec 2/3 de données d'entrainement et 1/3 de données test)
  #le modèle compare toujour à la première modalité (cover type = 1)
  #quand on prédit on a la probabilité que l'indiv soit dans la classe i / proba qu'il soit dans la classe 7
  ychap <- predict(mod, Cov_red[itest,],type="class") #faut transformer proba en catégorie (type=class)
  err[b] <- sum(ychap != Cov_red[itest,10])#on compte le nombre de fois où l'algorithme se trompe de cover type
  ychap_proba <- predict(mod, Cov_red[itest,],type = "probs")
  ychap2 <- ychap
  for (i in 1:length(ychap)) {
    if (sum(ychap_proba[i,3:7]>1/7)>0) {
      
    }
    else{
      
    }
    
  }
  #On veut sélectionner les variables qui ont de l'importance et les enregistrer dans une liste L
  
  #On utilise une pénalité lasso
}

T2<-Sys.time()

(Tdiff= difftime(T2, T1)) #dois tourner environ une heure

err_prob <- (rep(length(itest),length(err))-err) / length(itest) #quelle proportion des données sont correctement prédites
mean(err_prob) #moyenne des valeurs correctement prédites
sd(err_prob)

#On regarde les variables qui ressortent plus de 80% des fois

#remarque: modification possible: sortir les probabilités et attribuer les classes rares pour certaines probabilités même si ce ne sont pas les probabilités les plus fortes
#par exemple, si proba d'un cov type rare > 1/(nb cover type) alors on lui attribue ce cov type

```





